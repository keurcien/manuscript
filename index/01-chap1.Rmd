<!--
This is for including Chapter 1. Notice that it's also good practice to name your chunk. This will help you debug potential issues as you knit. The chunk above is called intro and the one below is called chapter1. Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from chap1.Rmd.
-->

<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1. These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase. Look for the reference to this label at the beginning of Chapter 2.
-->

# État de l'art

Cette section sera divisée en deux parties. La première partie traitera des méthodes destinées à identifier des loci sous sélection. Nous y présenterons l'heuristique des méthodes classiques de scan génomique pour la sélection. La seconde partie sera consacrée à la détection de signaux d'introgression. Par souci de clarté, nous ne considérerons ici que des espèces diploïdes, bien qu'une grande partie des résultats présentés ici puisse être adaptée au cas d'espèces haploïdes. Les loci seront par ailleurs supposés bi-alléliques, c'est-à-dire que pour un locus donné, au plus deux allèles sont observés sur ce locus à l'échelle de la population étudiée.

## Adaptation locale

### Modèles démographiques

Afin de mieux comprendre l'heuristique des méthodes de scan génomique présentées ici, nous donnons dans ce paragraphe une brève description des modèles démographiques fréquemment utilisés en génétique des populations. En effet l'idée de sélection dans une population est généralement relative à (au moins) une autre population, et la distribution des fréquences alléliques pour chacune de ces populations varie selon l'histoire démographique qu'elles ont connue.

#### Modèle en îles

Dans un modèle en îles, les différentes populations échangent entre elles des individus au cours du temps (Figure \@ref(fig:demographic-models)). La proportion d'individus échangée est appelée taux de migration. De forts taux de migration vont avoir tendance à homogénéiser les variations génétiques entre les populations. Des faibles taux de migration vont en revanche conduire à une différenciation plus forte. Les différences de taux de migration peuvent par exemple être expliquées par l'existence de barrières naturelles [@landguth2010relationships].

#### Modèle *star-like*

Le modèle *star-like* suppose l'existence d'une population ancestrale de laquelle sont issues différentes populations (Figure \@ref(fig:demographic-models)). Contrairement au modèle en îles, les populations évoluent de façon indépendante sans s'échanger d'individus, et se différencient éventuellement sous l'effet de la dérive génétique et de mutations aléatoires. Le modèle de divergence instantanée est un modèle *star-like* particulier, dans lequel les populations ont divergé au même moment (Figure \@ref(fig:demographic-models)).

------

(ref:demographic-models-cap) Modèles démographiques. En haut à gauche, une représentation schématique d'un modèle en îles à trois populations. En haut à droite, une représentation schématique d'un modèle *star-like* à trois populations où les *branches* ont des longueurs inégales. En bas à gauche, une représentation schématique d'un modèle de divergence instantanée à trois populations où chaque branche a la même longueur.

```{r demographic-models, fig.cap='(ref:demographic-models-cap)'}
circleFun <- function(center = c(0, 0),
                      diameter = 1,
                      npoints = 100,
                      start = 0,
                      end = 2,
                      filled = TRUE){
  tt <- seq(start * pi, end * pi, length.out = npoints)
  df <- data.frame(
    x = center[1] + diameter / 2 * cos(tt),
    y = center[2] + diameter / 2 * sin(tt)
  )

  if (filled) { #add a point at the center so the whole 'pie slice' is filled
    df <- rbind(df, center)
  }

  return(df)
}

### Figure A
triangle.x <- c(0, 1, 2)
triangle.y <- c(0, sqrt(3), 0)
df.triangle <- data.frame(x = triangle.x, y = triangle.y)
df.branch <- data.frame(x1 = 0, x2 = 2, y1 = 0, y2 = 0)

diam <- 0.75
fullCircle.1 <- circleFun(c(0, 0), diam, start = 0, end = 2, filled = TRUE)
fullCircle.2 <- circleFun(c(1, sqrt(3)), diam, start = 0, end = 2, filled = TRUE)
fullCircle.3 <- circleFun(c(2, 0), diam, start = 0, end = 2, filled = TRUE)

p1 <- ggplot(df.triangle, aes(x = x, y = y)) +
  geom_line(size = 4, colour = "#E69F00") +
  geom_segment(data = df.branch,
               aes(x = x1, y = y1, xend = x2, yend = y2),
               size = 4,
               colour = "#E69F00") +
  geom_polygon(data = fullCircle.1, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.2, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.3, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  coord_equal() +
  annotate("text",
           x = triangle.x,
           y = triangle.y,
           label = c("bold(P)[1]", "bold(P)[2]", "bold(P)[3]"),
           parse = TRUE, size = 5) +
  xlim(-1.5, 3.5) +
  ylim(-1.5, 2.5) +
  xlab("") +
  ylab("") +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank())

### Figure B
triangle.x <- c(0.25, 1, 2)
triangle.y <- c(sqrt(3) / 4, sqrt(3), 0)
df.triangle <- data.frame(x = triangle.x, y = triangle.y)
df.branch <- data.frame(x1 = 1, x2 = 1, y1 = -1, y2 = sqrt(3))
fullCircle.4 <- circleFun(c(0.25, sqrt(3) / 4), diam, start = 0, end = 2, filled = TRUE)
fullCircle.5 <- circleFun(c(1, -1), diam, start = 0, end = 2, filled = TRUE)

p2 <- ggplot(df.triangle, aes(x = x, y = y)) +
  geom_line(size = 4, colour = "#E69F00") +
  geom_segment(data = df.branch,
               aes(x = x1, y = y1, xend = x2, yend = y2),
               size = 4,
               colour = "#E69F00") +
  geom_polygon(data = fullCircle.4, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.5, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.3, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  coord_equal() +
  annotate("text",
           x = c(0.25, 1, 2),
           y = c(sqrt(3) / 4, -1, 0),
           label = c("bold(P)[1]", "bold(P)[2]", "bold(P)[3]"),
           parse = TRUE, size = 5) +
  xlim(-1.5, 3.5) +
  ylim(-1.5, 2.5) +
  xlab("") +
  ylab("") +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank())

### Figure C
triangle.x <- c(0, 1, 2)
triangle.y <- c(0, sqrt(3), 0)
df.triangle <- data.frame(x = triangle.x, y = triangle.y)
df.branch <- data.frame(x1 = 1, x2 = 1, y1 = sqrt(3) - 2, y2 = sqrt(3))
fullCircle.6 <- circleFun(c(1, sqrt(3) - 2), diam, start = 0, end = 2, filled = TRUE)

p3 <- ggplot(df.triangle, aes(x = x, y = y)) +
  geom_line(size = 4, colour = "#E69F00") +
  geom_segment(data = df.branch,
               aes(x = x1, y = y1, xend = x2, yend = y2),
               size = 4,
               colour = "#E69F00") +
  geom_polygon(data = fullCircle.1, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.6, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  geom_polygon(data = fullCircle.3, aes(x, y), color = "#56B4E9", fill = "#56B4E9") +
  coord_equal() +
  annotate("text",
           x = c(0, 1, 2),
           y = c(0, sqrt(3) - 2, 0),
           label = c("bold(P)[1]", "bold(P)[2]", "bold(P)[3]"),
           parse = TRUE, size = 5) +
  xlim(-1.5, 3.5) +
  ylim(-1.5, 2.5) +
  xlab("") +
  ylab("") +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank())

cowplot::plot_grid(p1, p2, p3, labels = c("A", "B", "C"), ncol = 2)
```

### L'indice de fixation

Indépendamment de l'histoire démographique, un allèle sélectionné voit généralement sa prévalence augmenter au sein d'une population. Si bien que l'observation d'une fréquence allélique anormalement élevée dans une population relativement aux autres suggère fortement que cet allèle a été favorablement sélectionné. De ce constat, il semble alors naturel de proposer une statistique testant si au moins deux populations présentent des fréquences alléliques significativement différentes l'une de l'autre [@holsinger2009genetics]. L'indice de fixation, ou encore $F_{ST}$ en abrégé, est une statistique basée sur cette heuristique. Pour un locus donné, dénotant $N$ le nombre de populations considérées et ($p_1, p_2, \dots, p_N$) les fréquences d'un des deux allèles existant, la $F_{ST}$ est définie par la relation suivante :

\begin{equation}
  F_{ST} = \frac{\frac{1}{N-1}\sum_{i = 1}^N (p_i - \bar{p})^2}{\bar{p}(1 - \bar{p})}
  (\#eq:fst-definition)
\end{equation}

où $\bar{p} = \frac{1}{N-1}\sum_{i = 1}^N p_i$. Le numérateur correspond à la variance génétique interpopulationnelle tandis que le dénominateur correspond à la variance génétique mesurée à l'échelle de la *métapopulation*^[ensemble de populations d'individus appartenant à la même espèce.]. La variance génétique est appelée aussi *degré d'hétérozygotie*. Relativement à l'hétérozygotie, la $F_{ST}$ peut être vue comme la réduction d'hétérozygotie due à la structure de population. Autrement dit, on regarde si le fait de grouper les individus dans des populations a une incidence ou non sur le degré d'hétérozygotie.

### Test de Lewontin-Krakauer

Comme expliqué plus haut, la détection de loci sous sélection passe généralement par la caractérisation d'un modèle décrivant l'évolution de loci sous l'effet de processus neutres tels que la dérive génétique. Ce principe renvoie en statistiques à la notion de test d'hypothèse. Les tests d'hypothèse sont particulièrement intéressants lorsque l'on cherche à évaluer la probabilité qu'un évènement a de se produire. Dans le cas des scans génomiques, il s'agit d'estimer la distribution neutre de la statistique de test (calculée en chaque locus), afin d'identifier les loci qui s'en écartent le plus.

Suivant ce principe, Lewontin et Krakauer proposent pour la $F_{ST}$ un test d'adéquation du $\chi^2$  [@lewontin1973distribution] :

\begin{equation}
  T_{LK} = \frac{N - 1}{\bar{F}_{ST}} F_{ST}
  (\#eq:LK-test)
\end{equation}

Dans un scénario de divergence instantanée (Figure \@ref(fig:demographic-models)), sous l'hypothèse que les fréquences alléliques sont distribuées selon une loi normale ou binomiale, $T_{LK}$ suit une loi du $\chi^2$ à $N-1$ degrés de libertés [@lewontin1973distribution]. En effet, en utilisant la définition de la $F_{ST}$ \@ref(eq:fst-definition) et en remarquant que :

\begin{equation}
  (N-1)F_{ST} = \frac{1}{\bar{p}(1 - \bar{p})}\sum_{i = 1}^N (p_i - \bar{p})^2 = \left(\frac{\boldsymbol{p} - \bar{p}}{\sqrt{\bar{p}(1-\bar{p})}}\right) \left(\frac{\boldsymbol{p} - \bar{p}}{\sqrt{\bar{p}(1-\bar{p})}}\right) ^T
  (\#eq:LK-chi2)
\end{equation}

il est possible de réécrire $T_{LK}$ sous la forme d'une somme quadratique de lois normales.
Cependant, les contraintes sur le modèle démographique sous-jacent sont extrêmement fortes et il est raisonnable de penser que celles-ci ne seront vraisemblablement pas toujours vérifiées. Des variantes de ce test ont donc été proposées pour s'adapter à des modèles plus généraux.

#### Estimation du nombre de degrés de liberté effectif

Dans le cas où les populations n'évoluent pas de façon indépendante (ce qui peut être le cas s'il y a eu de l'isolement par la distance par la distance), la statistique $T_{LK}$ n'est plus distribuée selon un $\chi^2$ à $N-1$ degrés de liberté. Ce test peut cependant être rendu valable en estimant le nombre de degrés effectif $\text{df}$ de la statistique $T_{LK}$ [@whitlock2015reliable]. Pour estimer $\text{df}$, Whitlock, *et al* dérivent un modèle de vraisemblance basé sur la distribution de la $F_{ST}$. Partant de la densité d'une variable aléatoire suivant un $\chi^2$ à $\text{df}$ degrés de libertés, la densité de la $F_{ST}$ s'écrit :

\begin{equation}
  f(F_{ST}) = \frac{\text{df}}{\bar{F}_{ST}} \times \frac{1}{2^{\frac{\text{df}}{2}}\Gamma\left(\frac{\text{df}}{2}\right)} \times  \left(\frac{\text{df}}{\bar{F}_{ST}}F_{ST}\right)^{-1+\frac{\text{df}}{2}}
  (\#eq:OutFLANK-f)
\end{equation}

Notant $\hat{\text{df}} = \text{argmin}_{\text{df}} \; \sum_{i=1}^p \log(f(F_{ST}^i))$ l'estimateur du maximum de vraisemblance (où $F_{ST}^i$ désigne la $F_{ST}$ observée pour l'allèle $i$), la correction du test de Lewontin-Krakauer consiste à tester l'adéquation de $\frac{\hat{\text{df}}}{\bar{F}_{ST}}F_{ST}$ à un $\chi^2$ à $\hat{\text{df}}$ degrés de liberté.

#### Dérivation du test de Lewontin-Krakauer dans le cas de populations structurées

Dans le cas de populations structurées, l'hypothèse de divergence instantanée ne tient plus. Pour tenir compte de la structure, Bonhomme, *et al.* proposent de corriger la statistique pour l'apparentement génétique^[kinship.] des populations, modélisé par une matrice $\mathcal{F} = (f_{ij})_{1 \leq i,j \leq N} \in M_N(\mathbb{R})$, où $f_{ij}$ mesure la corrélation entre $p_i$ et $p_j$ et peut être interprétée comme la probabilité qu'un individu de la population $i$ et un individu de la population $j$ aient hérité de cet allèle d'un même ancêtre commun. 

La statistique de test $T_{F-LK}$, correspondant au test de Lewontin-Krakauer corrigé pour l'apparentement génétique $\mathcal{F}$, garde une forme analogue à celle développée en \@ref(eq:LK-chi2) :

\begin{equation}
   T_{F-LK} = \left(\frac{\boldsymbol{p} - \hat{p}_0}{\sqrt{\hat{p}_0(1-\hat{p}_0)}}\right) \mathcal{F}^{-1} \left(\frac{\boldsymbol{p} - \hat{p}_0}{\sqrt{\hat{p}_0(1-\hat{p}_0)}}\right)^T
  (\#eq:flk-statistic)
\end{equation}

où $\hat{p}_0$ désigne un estimateur de la fréquence $p_0$ de l'allèle dans la population ancestrale. 
Dans le cas où les loci sont soumis uniquement à la dérive génétique, $T_{F-LK} \sim \chi_{N - 1}^2$ [@bonhomme2010detecting]. En pratique, la méthode implémentée dans le logiciel hapflk cherche à estimer les paramètres $p_0$ et $\mathcal{F}$.

### Modèle du logiciel Bayescan

Une autre l'idée consiste à affirmer qu'en l'absence de sélection, dans un modèle en îles où des individus migrent d'une population à une autre, la proportion $\lambda$ d'allèles dans une population donnée provenant d'une autre population doit être la même pour tous les loci [@beaumont2004identifying]. Un locus présentant une proportion d'allèles migrants anormalement plus basse serait alors considéré comme potentiellement sous sélection [@petry1983effect; @bazin2010likelihood]. Sous l'hypothèse que les fréquences alléliques suivent une distribution bêta, la $F_{ST}$ peut se réécrire en fonction de la proportion $\lambda$ d'allèles migrants [@balding2003likelihood; @balding2008handbook] :

\begin{equation}
  F_{ST} = \frac{1}{1 + \lambda}
  (\#eq:fst-balding)
\end{equation}

DEMO EN ANNEXE

Réécrite de cette manière, elle peut être interprétée comme étant proportionnelle à la probabilité que deux individus aient un ancêtre commun dans la sous-population $j$. La façon la plus simple serait de modéliser à l'aide d'une régression linéaire la proportion $\lambda_{ij}$ en fonction d'effets $\alpha_i$ spécifiques au locus (*i.e.* taux de mutation, sélection) et d'effets $\beta_j$ spécifiques à la population (*i.e.* taille de population effective, taux de migration) :

\begin{equation}
  \lambda_{ij} = \alpha_i + \beta_j + \gamma_{ij}
  (\#eq:fst-linear-regression)
\end{equation}

où $\gamma_{ij}$ correspond à un terme d'erreur spécifique au locus $i$ et à la sous-population $j$. Cette formulation \@ref(eq:fst-linear-regression) n'est cependant pas satisfaisante [@beaumont2004identifying]. Si l'effet d'une population est très fort, les valeurs de $F_{ST}$ relativement à cette population se retrouveraient très faibles pour tous les loci, ce qui n'est pas désirable pour la détection de loci *outliers*. Pour contrer cet effet, Beaumont, *et al.* se tournent vers un modèle de régression logistique pour la $F_{ST}$ :

\begin{equation}
  \log \left( \frac{F_{ST}}{1 - F_{ST}} \right) = \alpha_i + \beta_j + \gamma_{ij}
  (\#eq:Bayescan-statistic-implicit)
\end{equation}

ce qui donne en version explicite :

\begin{equation}
  F_{ST} = \frac{\exp(\alpha_i + \beta_j + \gamma_{ij})}{1 + \exp(\alpha_i + \beta_j + \gamma_{ij})}
  (\#eq:Bayescan-statistic-explicit)
\end{equation}

```{r, eval=FALSE}
x <- seq(0, 10, by = 0.05)
data.frame(x = c(x, x),
           y = c(1 / (1 + 0.5 + x), exp(0.5 + x) / (1 + exp(0.5 + x))),
           model = c(rep("linear", length(x)), rep("logistic", length(x)))) %>%
  ggplot(aes(x = x, y = y, color = model)) +
  xlab(expression(beta)) +
  ylab(expression(F[ST])) +
  geom_line() +
  facet_grid(~model) +
  theme_bw()
```


### Fast PCA

#### L'ACP en génétique des populations

L'utilisation de l'Analyse en Composantes Principales en génétique des populations a été popularisée par Cavalli-Sforza [@menozzi1978synthetic].

(ref:popres-cap) ACP réalisée sur le jeu de données POPRES [@novembre2008genes].

```{r popres, fig.cap = '(ref:popres-cap)', out.width='\\textwidth'}
obj.popres <- readRDS("data/popres.rds")

ggdf <- data.frame(PC1 = -obj.popres$u[, 1],
                   PC2 = -obj.popres$u[, 2],
                   pop = obj.popres$pop.fr)

ggplot(ggdf, aes(x = PC2, y = PC1, fill = pop)) +
  geom_point(size = 2.5, shape = 21, stroke = 1) +
  scale_fill_manual(labels = sort(unique(ggdf$pop)),
                    values = as.character(obj.popres$palette.fr)) +
  guides(fill = guide_legend(nrow = 5)) +
  theme_bw() +
  theme(axis.text = element_text(face = "bold"),
        legend.text = element_text(size = 7.5),
        legend.key.height = unit(0.75, "line"),
        legend.key.width = unit(0.5, "line"),
        legend.title = element_blank(),
        legend.direction = "horizontal",
        legend.position = "bottom")
```

(ref:hapmap-cap) ACP réalisée sur la phase 3 du jeu de données HapMap [@gibbs2003international].

```{r hapmap, fig.cap = '(ref:hapmap-cap)', out.width='\\textwidth'}
obj.hapmap <- readRDS("data/hapmap.rds")

ggdf <- data.frame(PC1 = obj.hapmap$u[, 1],
                   PC2 = obj.hapmap$u[, 2],
                   pop = obj.hapmap$pop)

ggplot(ggdf, aes(x = PC1, y = PC2, fill = pop)) +
  geom_point(size = 2.5, shape = 21, stroke = 1) +
  scale_fill_manual(labels = sort(unique(ggdf$pop)),
                    values = as.character(obj.popres$palette.fr[1:length(unique(obj.hapmap$pop))])) +
  guides(fill = guide_legend(nrow = 1)) +
  theme_bw() +
  theme(axis.text = element_text(face = "bold"),
        legend.text = element_text(size = 7.5),
        legend.key.height = unit(0.75, "line"),
        legend.key.width = unit(0.5, "line"),
        legend.title = element_blank(),
        legend.direction = "horizontal",
        legend.position = "bottom")
```

### Contexte

### Tests multiples

### Contrôle du taux de fausse découverte

Le taux de fausse découverte, correspond à la proportion de faux positifs parmi les positifs. En notant $FP$ le nombre de faux positifs, $FP$ le nombre de vrais positifs, on définit le taux de fausse découverte $FDR$ par :

\begin{equation}
  FDR = \mathbb{E}\Big[\frac{FP}{TP + FP} 1_{FP+TP > 0}\Big]
  (\#eq:FDR-def)
\end{equation}

- Référence cours de Christophe Giraud

q-value, bonferroni, benjamini-hochberg
La figure suivante donne les comparaisons entre les différentes procédures de correction :

## Introgression adaptative

### Coefficients de métissage globaux et locaux

Étant données des populations ancestrales, il est possible d'estimer pour un individu donné, la proportion de son génôme provenant de chacune des populations ancestrales. Ces proportions sont connues plus communément sous le nom de *coefficients de métissage globaux*. De nombreux logiciels existent pour l'estimation de ces coefficients : STRUCTURE, ADMIXTURE [@alexander2009fast], LEA [@frichot2015lea], tess3r [@caye2016tess3]. En complément à cette information globale, il peut être intéressant de déterminer sur des portions plus petites du génôme, de la même manière que dans le cas global, les proportions venant de telle ou telle population ancestrale pour chacune de ces portions. Nous parlons dans ce cas de *coefficients de métissage locaux*. Encore une fois, plusieurs logiciels ont été proposés dans le but d'estimer ces coefficients : Hapmix [@price2009sensitive], EILA [@yang2013efficient], LAMP [@thornton2014local], loter ou encore RFmix [@maples2013rfmix].

L'introgression peut être détectée de différentes façons. Une première approche consiste à utiliser les *coefficients de métissage locaux*. Les méthodes mentionnées plus haut estiment ces coefficients pour chaque individu, permettant de calculer à partir de ceux-ci des coefficients de métissage locaux pour chaque population.

### Lien entre Analyse en Composantes Principales et métissage global.

L'un des premiers articles à établir un lien entre l'ACP et les coefficients de métissage global fut sur l'interprétation généalogique de l'ACP de Gil McVean [@mcvean2009genealogical]:

(ref:mcvean-cap) Coefficients de métissage et ACP [@mcvean2009genealogical].

```{r mcvean, results = 'asis', fig.cap = '(ref:mcvean-cap)', out.width = '300px'}
include_graphics("figure/mcvean.png")
```

Pour chacun des 22 chromosomes,

### Analyse en Composantes Principales locale

Notant $p$ le nombre de marqueurs génétiques, $i$ un entier compris entre $1$ et $p$, et $x_i$ la position génétique (en Morgans) ou la position physique (en paires de bases) du $i$-ème marqueur génétique. Nous définissons pour cet entier $i$ la fenêtre $W_i^T$ de taille $T$ et centrée en $i$ :

$$W_i^T = \{ j \in [|1, p|], |x_i - x_j| \leq T/2 \}$$

### Sensibilité à l'imputation des données manquantes

\newpage

#### Méthodes de détection

##### La statistique D de Patterson

La statistique $D$ de Patterson [@durand2011testing] demeure aujourd'hui la méthode la plus utilisée pour détecter la trace de flux de gènes dans une population. La méthode repose sur l'observation de motifs portant les noms *ABBA* et *BABA*, en référence aux différents types de généalogie possible pour un site nucléotidique.

$$ D = \displaystyle \frac{\sum_i C_{ABBA}(i) - C_{BABA}(i)}{\sum_i C_{ABBA}(i) + C_{BABA}(i)} $$

##### RNDmin

[Descriptif de RNDmin]

Pour comprendre la récente méthode proposée par [@rosenzweig2016powerful], il est nécessaire de définir un certain nombre de statistiques dont $RND_{\text{min}}$ dérive.

&nbsp;

- $d_{xy}$ est la distance de Hamming entre la séquence $X$ de la population $1$ et la séquence $Y$ de la population $2$. Ainsi, si $x = (x_i)_{1 \leq i \leq n}$ et $y = (y_i)_{1 \leq i \leq n}$, alors :

$$d_{xy} = \text{Card}(\{i \in [|1, n|] \; | \; x_i \neq y_i \})$$

Cette statistique est ainsi définie pour une paire de séquences ($x$, $y$). Pour quantifier la dissimilarité entre deux ensembles de séquences, deux approches sont possibles. La première consiste à calculer la distance moyenne $d_{XY}$. De par sa définition, cette distance présente néanmoins le défaut d'être peu sensible aux épisodes récents d'introgression [@geneva2015new].
En effet, les faibles valeurs de $d_{xy}$ correspondant à des évènements de divergence récents peuvent voir leur influence diminuée en cas de présence d'évènements de divergence plus anciens.
Pour pallier à ce problème, considérer la distance minimale entre les deux ensembles de séquences [@joly2009statistical] constitue une solution intéressante.

[Expliquer pourquoi on définit $d_{\text{out}}$ et $RND$]

En définissant $d_{out} = \frac{1}{2}(d_{XO} + d_{YO})$, il est possible de définir de la même
façon $RND_{min}$ :

$$RND_{\text{min}} = \frac{d_{\text{min}}}{d_{\text{out}}}$$

Pour récapituler, $RND_{\text{min}}$ est une statistique robuste aux variations de taux de mutation et qui reste sensible aux récents évènements d'introgression. En pratique, l'introduction de $d_{\text{out}}$ requiert ainsi la donnée d'une population ancestrale commune aux deux populations d'intérêt.

##### Bdf

##### Analyse Linéaire Discriminante

##### Régression linéaire, régression logistique, forêts aléatoires et importance des variables

##### Régression locale, package mgcv, locfit, Backward selection strategy

##### ACP locale et espace de formes

