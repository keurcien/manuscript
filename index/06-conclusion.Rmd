# Conclusions et perspectives 

Alors que le développement technologique des ressources de calcul semble s'essouffler, du fait de la difficulté croissante liée à la miniaturisation des semi-conducteurs, les données ne cessent quant à elles de s'accumuler, et ce, quelque soit le domaine d'activité. Cette tendance suggère l'utilisation d'algorithmes à faible complexité pour le traitement et l'analyse de ces données. L'Analyse en Composantes Principales se révèle donc être un outil de premier choix pour traiter ces nouveaux volumes de données. En génétique des populations, elle présente l'avantage supplémentaire de très bien s'interpréter par l'intermédiaire de la structure de populations. Pour ces raisons, nous avons développé au cours de cette thèse des méthodes statistiques reposant exclusivement sur l'Analyse en Composantes Principales.

Dans le chapitre 2, nous avons montré comment l'utilisation de l'ACP permettait d'étendre les tests classiques de différenciation au cas de populations continues. D'abord parce que l'indice de fixation peut être vu comme la proportion de variance expliquée par un modèle à facteurs discrets, alors que la statistique de communalité renvoie à un modèle à facteurs qui peuvent être discrets ou continus. Ensuite parce que, de la même manière que notre nouvelle statistique, la statistique $T_{F-LK}$ correspond essentiellement à une distance de Mahalanobis dans le cas de populations discrètes.

Dans le chapitre 3, nous proposons une nouvelle approche statistique pour la détection de régions introgressées, basée sur l'utilisation de scores de métissage locaux calculés à partir de l'ACP. Les avantages de cette méthode, par rapport à celles qui sont présentées, sont essentiellement pratiques. La détection de l'introgression via l'estimation des coefficients de métissage locaux requiert souvent l'utilisation conjointe d'une méthode de phasage. De plus, notre méthode est de complexité linéaire par rapport au nombre d'individus ainsi que par rapport au nombre de SNPs, ce qui la rend très rapide à utiliser même pour des jeux de données contenant 1,000,000 de SNPs ou plus.

Nous explorons dans ce chapitre les extensions ou alternatives possibles à ce qui a été présenté dans ce manuscript.

## Substitution de l'Analyse en Composantes Principales

La méthode de scan à sélection basée sur la distance de Mahalanobis peut être vue comme la succession de trois étapes :

- une première étape visant à déterminer la structure de populations à partir de l'ACP. 

- une deuxième étape consistant à effectuer la régression linéaire multiple de la matrice de génotypes normalisée par les scores de l'ACP.

- une troisième étape calculant la distance de chaque marqueur génétique à la moyenne de ces marqueurs pour une métrique donnée, ce qui permet d'identifier les marqueurs génétiques dont les coefficients de régression sont excessivement corrélés avec une ou plusieurs composantes principales. Dans le cas de la distance de Mahalanobis, la métrique est donnée par l'estimateur robuste de la matrice de covariance.

En réalité, on retrouve ce schéma également pour le calcul de la $F_{ST}$ :

- structure de populations définie par la matrice de scores $U_{\delta}$ telle qu'elle est définie dans le chapitre 1. 

- régression linéaire multiple de la matrice de $\tilde{G}$ par les scores $U_{\delta}$.

- calcul de la distance euclidienne $||\tilde{G}^TU_{\delta}||_2$ de chaque marqueur à la moyenne des marqueurs (ici la métrique est la matrice identité et la moyenne des marqueurs est la fréquence).

De la même façon, le schéma de calcul de $T_{F-LK}$ peut être transposé à celui décrit ci-dessus. Ces trois étapes communes permettent donc de définir un schéma général pour le développement de nouvelles méthodes de scan génomique. Nous proposons ici des alternatives calquées sur ce schéma qui peuvent se révéler intéressantes pour la détection de gènes sous adaptation locale.

### Utilisation du déséquilibre de liaison pour améliorer l'inférence de la structure

Lorsque deux marqueurs génétiques sont proches l'un de l'autre, il y a de fortes chances qu'ils soient corrélés entre eux. Ce phénomène est connu sous le nom de déséquilibre de liaison. Lors de l'inférence de la structure de populations à l'aide de l'ACP, il est généralement recommandé de filtrer ce déséquilibre de liaison en effectuant une procédure de *pruning* [@abdellaoui2013population; @prive2017efficient]. À l'inverse, @lawson2012inference suggèrent quant à eux d'inclure cette information et montrent qu'en utilisant leur logiciel fineSTRUCTURE sur des jeux de données denses, la structure de populations est bien mieux estimée qu'avec l'ACP telle qu'elle est implémentée dans EIGENSTRAT [@price2006principal]. L'utilisation de fineSTRUCTURE ou de méthodes qui prennent en compte le déséquilibre de liaison pour inférer la structure de populations peut donc s'avérer intéressante pour deux raisons. Cela permettrait de ne pas avoir à prétraiter les données pour le déséquilibre de liaison puisqu'il est directement pris en compte. Et surtout, nous nous attendons à ce qu'une meilleure estimation de la structure de population améliore la puissance des test statistiques et réduise le nombre de fausses découvertes. En pratique, pour définir un scan à sélection prenant en compte le déséquilibre de liaison pour l'estimation de la structure, il suffit d'utiliser les scores de l'ACP obtenus avec fineSTRUCTURE à la première étape.

### Utilisation de variables environnementales

Une autre alternative possible serait la prise en compte de variables environnementales pour la détection d'adaptation locale. Notre méthode actuelle suppose que les locus sous adaptation locale devraient être excessivement corrélés avec la structure de populations, qui est représentée par les composantes principales. Dans le cas où la sélection n'est pas liée à la structure de population, notre méthode n'est plus adaptée. Pour illustrer cela, il suffit de considérer une simulation où les locus sous sélection ne sont pas du tout corrélés à la structure de populations, mais à des variables environnementales qui ne sont pas non plus corrélés à la structure de populations. Nous observons sur la figure \@ref(fig:rda-pca) que notre méthode ne détecte aucun des locus sous adaptation locale. Pour détecter des signaux de ce type, une approche consiste à décorréler les variables environnementales à l'aide d'une analyse des redondances (RDA) [@lasky2012characterizing]. Cette analyse produit des nouveaux scores qui sont des combinaisons linéaires des variables environnementales et qui peuvent être utilisées en lieu et places des scores de l'ACP réalisée sur les génotypes. Cette étape est suivie des étapes 2 (régression multiple) et 3 (distance robuste de Mahalanobis) décrites ci-dessus. Cette procédure fait l'objet d'un travail de recherche de Thibaut Capblancq, post-doctorant au Laboratoire d'Ecologie Alpine à Grenoble.

(ref:rda-pca-cap) Exemple de scan à sélection réalisé avec pcadapt sur une simulation réalisée par Éric Bazin contenant des locus sous sélection qui ne sont pas corrélés à la structure de la population. Les points rouges correspondent aux locus sous sélection pour la simulation. 

```{r rda-pca, fig.cap='(ref:rda-pca-cap)'}
x <- readRDS(file = "data/rda.rds")
x$G <- x$G[-c(101:300), ]
gt <- seq(1, 100, by = 10)
obj.pcadapt <- pcadapt(x$G, K = 2)
obj.rda <- rdadapt(x$G, x$env)
d <- covRob_cpp(obj.rda$v[, 1:3])

type <- rep("Locus neutre", nrow(x$G))
type[gt] <- "Locus sous sélection"
df.1 <- data.frame(x = 1:nrow(obj.pcadapt$stat),
                   stat = obj.pcadapt$stat,
                   type = type,
                   method = "pcadapt")
df.2 <- data.frame(x = 1:length(d$dist),
                   stat = d$dist,
                   type = type,
                   method = "rdadapt")

rbind(df.1, df.2) %>% 
  ggplot(aes(x = x, y = stat, color = type)) +
  geom_point() +
  xlab("Indice") +
  ylab("Distance de Mahalanobis") +
  facet_wrap(~method) +
  scale_color_manual(name = "",
                     values = c("black", "red")) +
  theme_bw() +
  theme(legend.position = "bottom")
```


### Analyse en Composantes Principales robuste

L'utilisation de la distance robuste de Mahalanobis nous a permis de découvrir des méthodes d'estimation robuste de la matrice de covariance. De même que la distance robuste de Mahalanobis, l'Analyse en Composantes Principales peut être rendue robuste en utilisant un estimateur robuste pour l'estimation de la matrice d'apparentement génétique. Nous avons déjà discuté de la nécessité d'estimer une matrice de covariance de façon robuste en présence de données aberrantes. Dans le cas de l'estimation de la covariance des $z$-scores, la matrice de covariance est de taille $K \times K$ où $K$ est le nombre de composantes principales retenues et le temps de calcul est donc raisonnable. Pour estimer la matrice d'apparentement de façon robuste,

```{r}
isl <- readRDS("data/div.rds")
G <- isl$geno
p <- apply(G, MARGIN = 1, FUN = function(X) {mean(X) / 2})
Gs <- scale(t(G), center = TRUE, scale = sqrt(2 * p * (1-p)))
cov <- covRob_cpp(t(Gs))
obj.svd <- RSpectra::svds(cov$cov, k = 2)
x <- pcadapt(isl$geno, K = 2, min.maf = 0)
```

### 